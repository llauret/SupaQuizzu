{
  "quiz": "Optimisation",
  "questions": [
    {
      "enonce": "Qu’est-ce qu’un problème d’optimisation ?",
      "reponses": [
        { "reponse": "Calculer la dérivée seconde de la fonction objectif.", "est_correcte": false },
        { "reponse": "Trouver dans l'ensemble des configurations Ω la solution minimisant la fonction objectif f.", "est_correcte": true },
        { "reponse": "Maximiser la fonction de coût sans contrainte.", "est_correcte": false },
        { "reponse": "Échantillonner aléatoirement le domaine sans évaluation de f.", "est_correcte": false }
      ]
    },
    {
      "enonce": "Comment passe-t-on d’un problème de minimisation à un problème de maximisation ?",
      "reponses": [
        { "reponse": "En prenant l’inverse multiplicatif de la fonction objectif.", "est_correcte": false },
        { "reponse": "En utilisant g(x) = –f(x).", "est_correcte": true },
        { "reponse": "En dérivant la fonction objectif et en cherchant son maximum.", "est_correcte": false },
        { "reponse": "En transposant la matrice de Hessienne.", "est_correcte": false }
      ]
    },
    {
      "enonce": "Quelle condition définit un minimum local pour une fonction f ?",
      "reponses": [
        { "reponse": "f(x') ≤ f(x) pour tout x dans un voisinage de x'.", "est_correcte": true },
        { "reponse": "f(x') ≥ f(x) pour tout x dans l’espace de recherche Ω.", "est_correcte": false },
        { "reponse": "f(x') = max f(x) sur Ω.", "est_correcte": false },
        { "reponse": "f(x') > f(x) pour tout x dans un voisinage de x'.", "est_correcte": false }
      ]
    },
    {
      "enonce": "Sur quoi repose une méthode de recherche locale ?",
      "reponses": [
        { "reponse": "Exploration par échantillonnage aléatoire.", "est_correcte": false },
        { "reponse": "Exploration de proche en proche selon un voisinage.", "est_correcte": true },
        { "reponse": "Utilisation d’une population de solutions potentielles.", "est_correcte": false },
        { "reponse": "Application systématique de dérivées secondes.", "est_correcte": false }
      ]
    },
    {
      "enonce": "Quand utilise-t-on préférentiellement une méthode stochastique ?",
      "reponses": [
        { "reponse": "Lorsque la fonction objectif est non dérivable ou bruitée et qu’il y a de nombreux extrema.", "est_correcte": true },
        { "reponse": "Lorsque la fonction objectif est quadratique et dérivable.", "est_correcte": false },
        { "reponse": "Lorsqu’on dispose de la forme analytique exacte de f.", "est_correcte": false },
        { "reponse": "Lorsque l’espace de recherche est extrêmement petit.", "est_correcte": false }
      ]
    },
    {
      "enonce": "Lequel de ces algorithmes est une métaheuristique stochastique ?",
      "reponses": [
        { "reponse": "Méthode de relaxation (Gauss–Seidel).", "est_correcte": false },
        { "reponse": "Recuit simulé.", "est_correcte": true },
        { "reponse": "Méthode du gradient conjugué.", "est_correcte": false },
        { "reponse": "Programmation linéaire.", "est_correcte": false }
      ]
    },
    {
      "enonce": "Que stipule le théorème No Free Lunch en optimisation ?",
      "reponses": [
        { "reponse": "Qu’il existe un algorithme universellement meilleur pour tous les problèmes.", "est_correcte": false },
        { "reponse": "Qu’en moyenne, tous les algorithmes ont des performances équivalentes sur l’ensemble des fonctions de coût.", "est_correcte": true },
        { "reponse": "Qu’un algorithme gradient est toujours optimal.", "est_correcte": false },
        { "reponse": "Qu’on ne peut pas résoudre de problèmes combinatoires.", "est_correcte": false }
      ]
    },
    {
      "enonce": "Qu’est-ce qu’un problème d’optimisation combinatoire ?",
      "reponses": [
        { "reponse": "Un problème dont Ω est un sous-ensemble de ℝⁿ et continu.", "est_correcte": false },
        { "reponse": "Un problème dont Ω est fini ou dénombrable (p.ex. sous‑ensemble de ℕⁿ).", "est_correcte": true },
        { "reponse": "Un problème sans fonction objective.", "est_correcte": false },
        { "reponse": "Un problème uniquement résolu par dérivation.", "est_correcte": false }
      ]
    },
    {
      "enonce": "Quel exemple illustre un problème combinatoire classique ?",
      "reponses": [
        { "reponse": "Problème du voyageur de commerce.", "est_correcte": true },
        { "reponse": "Optimisation d’un réseau continu d’antennes.", "est_correcte": false },
        { "reponse": "Recalage rigide d’images médicales.", "est_correcte": false },
        { "reponse": "Minimisation d’une fonction quadratique simple.", "est_correcte": false }
      ]
    },
    {
      "enonce": "Quelle est la forme générale d’un problème d’optimisation non linéaire à contraintes ?",
      "reponses": [
        { "reponse": "max f(x) sous h(x) = 0 uniquement.", "est_correcte": false },
        { "reponse": "min f(x) sous g(x) ≤ 0 et h(x) = 0.", "est_correcte": true },
        { "reponse": "min f(x) sans aucune contrainte.", "est_correcte": false },
        { "reponse": "min f(x) sous g(x) = 0 uniquement.", "est_correcte": false }
      ]
    },
    {
      "enonce": "Quelle méthode est déterministe en optimisation ?",
      "reponses": [
        { "reponse": "Algorithme évolutionnaire.", "est_correcte": false },
        { "reponse": "Recuit simulé.", "est_correcte": false },
        { "reponse": "Méthode de gradient.", "est_correcte": true },
        { "reponse": "Algorithme de colonies de fourmis.", "est_correcte": false }
      ]
    },
    {
      "enonce": "Quel exemple illustre une méthode exacte (non approchée) ?",
      "reponses": [
        { "reponse": "Programmation linéaire.", "est_correcte": true },
        { "reponse": "Algorithme génétique.", "est_correcte": false },
        { "reponse": "Recuit simulé.", "est_correcte": false },
        { "reponse": "Colonie de fourmis.", "est_correcte": false }
      ]
    },
    {
      "enonce": "Quel principe permet à une métaheuristique de voisinage d’échapper à un minimum local ?",
      "reponses": [
        { "reponse": "Autoriser parfois une dégradation temporaire de la fonction objectif.", "est_correcte": true },
        { "reponse": "Augmenter systématiquement le nombre de variables.", "est_correcte": false },
        { "reponse": "Réduire la taille de l’espace de recherche à chaque itération.", "est_correcte": false },
        { "reponse": "Utiliser uniquement des gradients pour se déplacer.", "est_correcte": false }
      ]
    },
    {
      "enonce": "Qu’est-ce que l’optimisation multiobjectif ?",
      "reponses": [
        { "reponse": "Considérer plusieurs fonctions objectif contradictoires simultanément.", "est_correcte": true },
        { "reponse": "Maximiser une seule fonction avec plusieurs variables.", "est_correcte": false },
        { "reponse": "Minimiser la somme des carrés d’une seule fonction.", "est_correcte": false },
        { "reponse": "Résoudre plusieurs problèmes indépendants l’un de l’autre.", "est_correcte": false }
      ]
    },
    {
      "enonce": "Qu’est-ce qu’une méthode hybride en optimisation ?",
      "reponses": [
        { "reponse": "Combiner plusieurs métaheuristiques complémentaires.", "est_correcte": true },
        { "reponse": "Appliquer uniquement la programmation linéaire.", "est_correcte": false },
        { "reponse": "Utiliser une seule stratégie de voisinage.", "est_correcte": false },
        { "reponse": "Réduire l’espace de recherche à un point fixe.", "est_correcte": false }
      ]
    },
    {
      "enonce": "Quel critère n’existe pas pour choisir un algorithme d’optimisation selon le cours ?",
      "reponses": [
        { "reponse": "Temps de calcul raisonnable.", "est_correcte": false },
        { "reponse": "Absence de recette miracle universelle.", "est_correcte": false },
        { "reponse": "Adaptation à la structure mathématique du problème.", "est_correcte": false },
        { "reponse": "Utiliser toujours le même algorithme pour tous les problèmes.", "est_correcte": true }
      ]
    },
    {
      "enonce": "La difficulté d’un problème d’optimisation est liée à quel facteur ?",
      "reponses": [
        { "reponse": "Nombre de variables à optimiser.", "est_correcte": true },
        { "reponse": "Qualité de l’interface graphique.", "est_correcte": false },
        { "reponse": "Marque du processeur utilisé.", "est_correcte": false },
        { "reponse": "Taille du code source seulement.", "est_correcte": false }
      ]
    },
    {
      "enonce": "Comment définit-on l'espace de recherche Ω ?",
      "reponses": [
        { "reponse": "L’ensemble des solutions admissibles du problème.", "est_correcte": true },
        { "reponse": "L’espace des images médicales pour recalage.", "est_correcte": false },
        { "reponse": "Le domaine des coefficients de la matrice Hessienne.", "est_correcte": false },
        { "reponse": "Le vecteur gradients de f.", "est_correcte": false }
      ]
    },
    {
      "enonce": "Quelle est la principale caractéristique d’une méthode stochastique ?",
      "reponses": [
        { "reponse": "Elle utilise des tirages aléatoires pour guider la recherche.", "est_correcte": true },
        { "reponse": "Elle dépend uniquement de la forme analytique de f.", "est_correcte": false },
        { "reponse": "Elle garantit toujours l’optimum global.", "est_correcte": false },
        { "reponse": "Elle n’explore jamais d’autres points que le point initial.", "est_correcte": false }
      ]
    },
    {
      "enonce": "Quel est l'objectif d'un problème d'optimisation ?",
      "reponses": [
        {
          "reponse": "Maximiser la variance des données d'entrée.",
          "est_correcte": false
        },
        {
          "reponse": "Trouver le minimum d'une fonction objective sur un ensemble de configurations.",
          "est_correcte": true
        },
        {
          "reponse": "Classer les échantillons selon des catégories prédéfinies.",
          "est_correcte": false
        },
        {
          "reponse": "Réduire la complexité algorithmique d'un programme.",
          "est_correcte": false
        }
      ]
    },
    {
      "enonce": "Qu'est-ce qu'une méthode d'optimisation locale et déterministe ?",
      "reponses": [
        {
          "reponse": "Un algorithme qui explore l'ensemble des solutions de façon aléatoire.",
          "est_correcte": false
        },
        {
          "reponse": "Une technique qui garantit de trouver le minimum global.",
          "est_correcte": false
        },
        {
          "reponse": "Un algorithme qui se base sur le gradient pour converger vers un minimum local.",
          "est_correcte": true
        },
        {
          "reponse": "Un processus analogique au refroidissement des métaux.",
          "est_correcte": false
        }
      ]
    },
    {
      "enonce": "Qu'est-ce qu'une méthode d'optimisation globale et stochastique ?",
      "reponses": [
        {
          "reponse": "Descente de gradient stochastique.",
          "est_correcte": false
        },
        {
          "reponse": "Recuit simulé.",
          "est_correcte": true
        },
        {
          "reponse": "Méthode de Newton.",
          "est_correcte": false
        },
        {
          "reponse": "Algorithme de dichotomie.",
          "est_correcte": false
        }
      ]
    },
    {
      "enonce": "Quelle est la formule de mise à jour de la descente de gradient en dimension 1 ?",
      "reponses": [
        {
          "reponse": "x_{k+1} = x_k + γ · f'(x_k).",
          "est_correcte": false
        },
        {
          "reponse": "x_{k+1} = x_k - γ · f'(x_k).",
          "est_correcte": true
        },
        {
          "reponse": "x_{k+1} = γ · x_k - f'(x_k).",
          "est_correcte": false
        },
        {
          "reponse": "x_{k+1} = x_k - f(x_k)/γ.",
          "est_correcte": false
        }
      ]
    },
    {
      "enonce": "Quel rôle joue le pas γ dans la descente de gradient ?",
      "reponses": [
        {
          "reponse": "Il fixe la température initiale dans le recuit simulé.",
          "est_correcte": false
        },
        {
          "reponse": "Il définit la taille de l'échantillon utilisé pour le calcul du gradient.",
          "est_correcte": false
        },
        {
          "reponse": "Il détermine la vitesse de convergence et peut influencer le minimum atteint.",
          "est_correcte": true
        },
        {
          "reponse": "Il correspond à la probabilité d'acceptation d'une configuration.",
          "est_correcte": false
        }
      ]
    },
    {
      "enonce": "Quels sont deux variants de la descente de gradient mentionnés ?",
      "reponses": [
        {
          "reponse": "Métropolis et Boltzmann.",
          "est_correcte": false
        },
        {
          "reponse": "Newton et quasi-Newton.",
          "est_correcte": false
        },
        {
          "reponse": "Batch et mini-batch.",
          "est_correcte": true
        },
        {
          "reponse": "Convolution et pooling.",
          "est_correcte": false
        }
      ]
    },
    {
      "enonce": "Quels sont les critères d'arrêt pour la descente de gradient ?",
      "reponses": [
        {
          "reponse": "Atteinte de l'énergie minimale globale garantie.",
          "est_correcte": false
        },
        {
          "reponse": "Stabilisation de la probabilité d'acceptation.",
          "est_correcte": false
        },
        {
          "reponse": "Augmentation de la température.",
          "est_correcte": false
        },
        {
          "reponse": "Variation négligeable de x ou nombre maximal d'itérations.",
          "est_correcte": true
        }
      ]
    },
    {
      "enonce": "Quelle condition caractérise un minimum d'une fonction dérivable ?",
      "reponses": [
        {
          "reponse": "f(x) = 0.",
          "est_correcte": false
        },
        {
          "reponse": "f'(x) = 0.",
          "est_correcte": true
        },
        {
          "reponse": "∇f(x) = 1.",
          "est_correcte": false
        },
        {
          "reponse": "f'(x) > 0.",
          "est_correcte": false
        }
      ]
    },
    {
      "enonce": "En dimension n, comment la descente de gradient est-elle généralisée ?",
      "reponses": [
        {
          "reponse": "x_{k+1} = x_k - γ · f'(x_k).",
          "est_correcte": false
        },
        {
          "reponse": "x_{k+1} = γ · ∇f(x_k).",
          "est_correcte": false
        },
        {
          "reponse": "x_{k+1} = ∇f(x_k) - γ · x_k.",
          "est_correcte": false
        },
        {
          "reponse": "x_{k+1} = x_k - γ · ∇f(x_k).",
          "est_correcte": true
        }
      ]
    },
    {
      "enonce": "Quelle analogie physique inspire le recuit simulé ?",
      "reponses": [
        {
          "reponse": "La polarisation magnétique des matériaux ferromagnétiques.",
          "est_correcte": false
        },
        {
          "reponse": "Le refroidissement progressif des métaux pour atteindre une structure cristalline.",
          "est_correcte": true
        },
        {
          "reponse": "La propagation d'ondes électromagnétiques.",
          "est_correcte": false
        },
        {
          "reponse": "La loi des gaz parfaits.",
          "est_correcte": false
        }
      ]
    },
    {
      "enonce": "Quelle distribution est utilisée pour modéliser l'acceptation dans le recuit simulé ?",
      "reponses": [
        {
          "reponse": "Distribution de Poisson.",
          "est_correcte": false
        },
        {
          "reponse": "Distribution uniforme sur [0,1].",
          "est_correcte": false
        },
        {
          "reponse": "Distribution de Gibbs / Boltzmann.",
          "est_correcte": true
        },
        {
          "reponse": "Distribution binomiale.",
          "est_correcte": false
        }
      ]
    },
    {
      "enonce": "Quel critère d'acceptation de la configuration y remplace la condition E(y) < E(x) ?",
      "reponses": [
        {
          "reponse": "P(y|x) = max(1, exp((E(y)-E(x))/T)).",
          "est_correcte": false
        },
        {
          "reponse": "P(y|x) = exp(E(y)/E(x)).",
          "est_correcte": false
        },
        {
          "reponse": "P(y|x) = min(1, exp(-(E(y)-E(x))/T)).",
          "est_correcte": true
        },
        {
          "reponse": "P(y|x) = (E(x)-E(y))/T.",
          "est_correcte": false
        }
      ]
    },
    {
      "enonce": "Quel est l'impact de la température T sur la probabilité d'acceptation dans le recuit simulé ?",
      "reponses": [
        {
          "reponse": "À haute T, seules les configurations d'énergie inférieure sont acceptées.",
          "est_correcte": false
        },
        {
          "reponse": "À basse T, toute configuration est acceptée.",
          "est_correcte": false
        },
        {
          "reponse": "La température n'a aucun impact.",
          "est_correcte": false
        },
        {
          "reponse": "À haute T, presque toutes les configurations sont acceptées.",
          "est_correcte": true
        }
      ]
    },
    {
      "enonce": "Quel schéma de décroissance de la température est mentionné ?",
      "reponses": [
        {
          "reponse": "T_k = T0 + k · α avec 0<α<1.",
          "est_correcte": false
        },
        {
          "reponse": "T_k = T0 × α^k avec 0<α<1.",
          "est_correcte": true
        },
        {
          "reponse": "T_k = T0 / (1 + k).",
          "est_correcte": false
        },
        {
          "reponse": "T_k = α · log(k).",
          "est_correcte": false
        }
      ]
    },
    {
      "enonce": "Quels paramètres doivent être ajustés pour le recuit simulé ?",
      "reponses": [
        {
          "reponse": "Le pas de gradient, la taille du mini-batch, et la fonction d'activation.",
          "est_correcte": false
        },
        {
          "reponse": "Le taux d'apprentissage initial, le momentum et le bias.",
          "est_correcte": false
        },
        {
          "reponse": "La température initiale, la longueur de palier et le schéma de décroissance.",
          "est_correcte": true
        },
        {
          "reponse": "Le nombre de couches cachées et la taille des neurones.",
          "est_correcte": false
        }
      ]
    },
    {
      "enonce": "Quelle équation stochastique combine descente de gradient et perturbation aléatoire ?",
      "reponses": [
        {
          "reponse": "dx_t = γ ∇f(x_t) dt + exp(-E/T) dw_t.",
          "est_correcte": false
        },
        {
          "reponse": "dx_t = -∇E(x_t) dt + √(2 T_t) dw_t.",
          "est_correcte": true
        },
        {
          "reponse": "x_{k+1} = x_k - γ ∇f(x_k) + noise.",
          "est_correcte": false
        },
        {
          "reponse": "dx_t = ∇E(x_t) dt - T_t dw_t.",
          "est_correcte": false
        }
      ]
    },
    {
      "enonce": "Dans l'équation de diffusion, quel terme correspond à la descente de gradient ?",
      "reponses": [
        {
          "reponse": "√(2 T_t) dw_t.",
          "est_correcte": false
        },
        {
          "reponse": "γ f'(x_k).",
          "est_correcte": false
        },
        {
          "reponse": "exp(-E/T) dw_t.",
          "est_correcte": false
        },
        {
          "reponse": "-∇E(x_t) dt.",
          "est_correcte": true
        }
      ]
    },
    {
      "enonce": "Et quel terme représente la perturbation aléatoire dans l'équation de diffusion ?",
      "reponses": [
        {
          "reponse": "-∇E(x_t) dt.",
          "est_correcte": false
        },
        {
          "reponse": "γ dt.",
          "est_correcte": false
        },
        {
          "reponse": "E(x_t) T_t.",
          "est_correcte": false
        },
        {
          "reponse": "√(2 T_t) dw_t.",
          "est_correcte": true
        }
      ]
    },
    {
      "enonce": "Quelles conditions sont requises pour garantir la convergence de l'équation de diffusion ?",
      "reponses": [
        {
          "reponse": "T_t doit être constant et dt grand.",
          "est_correcte": false
        },
        {
          "reponse": "μ doit être proche de 1 et α proche de 0.",
          "est_correcte": false
        },
        {
          "reponse": "T_t doit décroître suffisamment lentement et dt être petit.",
          "est_correcte": true
        },
        {
          "reponse": "T0 doit être nul au départ.",
          "est_correcte": false
        }
      ]
    },
    {
      "enonce": "Quelle différence principale existe-t-il entre la descente de gradient et le recuit simulé ?",
      "reponses": [
        {
          "reponse": "Le recuit simulé est toujours plus rapide.",
          "est_correcte": false
        },
        {
          "reponse": "La descente de gradient utilise toujours un mini-batch.",
          "est_correcte": false
        },
        {
          "reponse": "La descente de gradient nécessite une phase de refroidissement.",
          "est_correcte": false
        },
        {
          "reponse": "Le recuit simulé peut échapper aux minima locaux grâce à l'acceptation aléatoire.",
          "est_correcte": true
        }
      ]
    }
  ]
}
